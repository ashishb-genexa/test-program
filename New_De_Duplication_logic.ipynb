{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id FirstName  LastName            E-mail Address  Company  Job Title\n",
      "0   659  Fernando   2Forces                       NaN      NaN        NaN\n",
      "1   539      Todd  Abbrecht         tabbrecht@thl.com      NaN        NaN\n",
      "2  2184     Peter    Abdill   peter.abdill@moodys.com      NaN        NaN\n",
      "3  1782    Faysal  Abillama  faysal.abillama@hsbc.com      NaN        NaN\n",
      "4  1573     Salon     Above                       NaN      NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from Excel file\n",
    "file_path = './data/Subset-input data for Contact1 - Centerbridge - 3k 2.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "\n",
    "df.sort_values(by='LastName', inplace=True)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import ratio\n",
    "\n",
    "def is_similar(name1, name2, threshold=0.55):\n",
    "    return ratio(name1, name2) >= threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_last_name(df, threshold=0.85):\n",
    "    groups = []\n",
    "    for index, row in df.iterrows():\n",
    "        last_name = str(row['LastName'])  # Ensure last_name is a string\n",
    "        found_group = False\n",
    "        for group in groups:\n",
    "            # Check if the first character of the last name is the same\n",
    "            if last_name[0] == str(group[0]['LastName'])[0]:\n",
    "                if is_similar(last_name, str(group[0]['LastName']), threshold):\n",
    "                    group.append(row)\n",
    "                    found_group = True\n",
    "                    break\n",
    "        if not found_group:\n",
    "            groups.append([row])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old logic\n",
    "def group_by_last_name(df, threshold=0.8):\n",
    "    groups = []\n",
    "    for index, row in df.iterrows():\n",
    "        last_name = row['LastName']\n",
    "        found_group = False\n",
    "        for group in groups:\n",
    "            if is_similar(last_name, group[0]['LastName'], threshold):\n",
    "                group.append(row)\n",
    "                found_group = True\n",
    "                break\n",
    "        if not found_group:\n",
    "            groups.append([row])\n",
    "    return groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new logic with add first letter \n",
    "def refine_by_first_name(groups, threshold=0.65):\n",
    "    refined_groups = []\n",
    "    for group in groups:\n",
    "        refined_group = []\n",
    "        for contact in group:\n",
    "            first_name = str(contact.get('FirstName', ''))  # Ensure first_name is a string\n",
    "            if not first_name:\n",
    "                continue\n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0] or len(first_name) == 1:\n",
    "                    if is_similar(first_name, str(subgroup[0]['FirstName']), threshold) or len(first_name) == 1:\n",
    "                        subgroup.append(contact)\n",
    "                        found_subgroup = True\n",
    "                        break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        refined_groups.append(refined_group)\n",
    "    return refined_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_by_first_name(groups, threshold=0.65):\n",
    "    refined_groups = []\n",
    "    for group in groups:\n",
    "        refined_group = []\n",
    "        for contact in group:\n",
    "            first_name = str(contact['FirstName'])  # Ensure first_name is a string\n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                # Check if the first letter of the first name is the same\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0]:\n",
    "                    # Apply similarity check\n",
    "                    if is_similar(first_name, str(subgroup[0]['FirstName']), threshold):\n",
    "                        subgroup.append(contact)\n",
    "                        found_subgroup = True\n",
    "                        break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        refined_groups.append(refined_group)\n",
    "    return refined_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without_First_name_first_letter_Matching\n",
    "def refine_by_first_name(groups, threshold=0.68):\n",
    "    refined_groups = []\n",
    "    for group in groups:\n",
    "        refined_group = []\n",
    "        for contact in group:\n",
    "            first_name = contact['FirstName']\n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if is_similar(first_name, subgroup[0]['FirstName'], threshold) or (len(first_name) == 1 and first_name == subgroup[0]['FirstName'][0]):\n",
    "                    subgroup.append(contact)\n",
    "                    found_subgroup = True\n",
    "                    break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        refined_groups.append(refined_group)\n",
    "    return refined_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old One\n",
    "def refine_by_first_name(groups, threshold=0.68):\n",
    "    refined_groups = []\n",
    "    for group in groups:\n",
    "        refined_group = []\n",
    "        for contact in group:\n",
    "            first_name = contact['FirstName']\n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if is_similar(first_name, subgroup[0]['FirstName'], threshold):\n",
    "                    subgroup.append(contact)\n",
    "                    found_subgroup = True\n",
    "                    break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        refined_groups.append(refined_group)\n",
    "    return refined_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ids(refined_groups):\n",
    "    group_id = 1\n",
    "    subgroup_id = 1  # Initialize a global counter for SubgroupID\n",
    "    result = []\n",
    "    for group in refined_groups:\n",
    "        for subgroup in group:\n",
    "            is_duplicate = len(subgroup) > 1\n",
    "            for contact in subgroup:\n",
    "                if is_duplicate:\n",
    "                    contact['GroupID'] = group_id\n",
    "                    contact['SubgroupID'] = subgroup_id\n",
    "                else:\n",
    "                    contact['GroupID'] = group_id\n",
    "                    contact['SubgroupID'] = 9999999  # No subgroup ID for unique records\n",
    "                contact['IsDuplicate'] = is_duplicate\n",
    "                result.append(contact)\n",
    "            if is_duplicate:\n",
    "                subgroup_id += 1  # Increment the global SubgroupID counter only for duplicates\n",
    "        group_id += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ids(refined_groups):\n",
    "    group_id = 1\n",
    "    subgroup_id = 1  # Initialize a global counter for SubgroupID\n",
    "    result = []\n",
    "    for group in refined_groups:\n",
    "        for subgroup in group:\n",
    "            for contact in subgroup:\n",
    "                contact['GroupID'] = group_id\n",
    "                contact['SubgroupID'] = subgroup_id\n",
    "                contact['IsDuplicate'] = len(subgroup) > 1\n",
    "                result.append(contact)\n",
    "            subgroup_id += 1  # Increment the global SubgroupID counter\n",
    "        group_id += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "def assign_ids(refined_groups):\n",
    "    group_id = 1\n",
    "    result = []\n",
    "    for group in refined_groups:\n",
    "        subgroup_id = 1\n",
    "        for subgroup in group:\n",
    "            for contact in subgroup:\n",
    "                contact['GroupID'] = group_id\n",
    "                contact['SubgroupID'] = subgroup_id\n",
    "                contact['IsDuplicate'] = len(subgroup) > 1\n",
    "                result.append(contact)\n",
    "            subgroup_id += 1\n",
    "        group_id += 1\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_by_first_name(groups, threshold=0.65):\n",
    "    refined_groups = []\n",
    "    for group in groups:\n",
    "        refined_group = []\n",
    "        single_letter_names = []\n",
    "        \n",
    "        for contact in group:\n",
    "            first_name = str(contact.get('FirstName', ''))  # Ensure first_name is a string\n",
    "            if not first_name:\n",
    "                continue\n",
    "            if len(first_name) == 1:\n",
    "                single_letter_names.append(contact)\n",
    "                continue\n",
    "            \n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0]:\n",
    "                    if is_similar(first_name, str(subgroup[0]['FirstName']), threshold):\n",
    "                        subgroup.append(contact)\n",
    "                        found_subgroup = True\n",
    "                        break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        \n",
    "        # Integrate single-letter names into the appropriate subgroups\n",
    "        for contact in single_letter_names:\n",
    "            first_name = str(contact.get('FirstName', ''))\n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0]:\n",
    "                    subgroup.append(contact)\n",
    "                    found_subgroup = True\n",
    "                    break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        \n",
    "        refined_groups.append(refined_group)\n",
    "    \n",
    "    return refined_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id FirstName  LastName            E-mail Address  Company  Job Title  \\\n",
      "0   659  Fernando   2Forces                       NaN      NaN        NaN   \n",
      "1   539      Todd  Abbrecht         tabbrecht@thl.com      NaN        NaN   \n",
      "2  2184     Peter    Abdill   peter.abdill@moodys.com      NaN        NaN   \n",
      "3  1782    Faysal  Abillama  faysal.abillama@hsbc.com      NaN        NaN   \n",
      "4  1573     Salon     Above                       NaN      NaN        NaN   \n",
      "\n",
      "   GroupID  SubgroupID  IsDuplicate  \n",
      "0        1     9999999        False  \n",
      "1        2     9999999        False  \n",
      "2        3     9999999        False  \n",
      "3        4     9999999        False  \n",
      "4        5     9999999        False  \n"
     ]
    }
   ],
   "source": [
    "broad_groups = group_by_last_name(df)\n",
    "\n",
    "# Refine by first name\n",
    "refined_groups = refine_by_first_name(broad_groups)\n",
    "\n",
    "# Assign unique IDs and flag duplicates\n",
    "processed_contacts = assign_ids(refined_groups)\n",
    "\n",
    "# Convert processed contacts back to DataFrame\n",
    "processed_df = pd.DataFrame(processed_contacts)\n",
    "print(processed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv('./Subset-input data for COntact - Centerbridge - 3k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Fname      Lname Cleaned_Fname Cleaned_Lname\n",
      "0         John        Doe          John           Doe\n",
      "1         J√∂hn         D≈ì          J√∂hn            D≈ì\n",
      "2   Anna-Marie   O'Connor    Anna-Marie      O'Connor\n",
      "3         Jos√©     Garc√≠a          Jos√©        Garc√≠a\n",
      "4         M√•rk      Smith          M√•rk         Smith\n",
      "5     El≈ºbieta   Kowalski      El≈ºbieta      Kowalski\n",
      "6        Andr√©       T√≥th         Andr√©          T√≥th\n",
      "7       S√ºmmer     M√ºller        S√ºmmer        M√ºller\n",
      "8    T√≥TPœÜœàŒªŒ∑‚àû    Johnson     T√≥TPœÜœàŒªŒ∑‚àû       Johnson\n",
      "9        L√∫cia  Fern√°ndez         L√∫cia     Fern√°ndez\n",
      "10     AŒ±Œ≤ŒìŒîŒïŒ∂      Brown       AŒ±Œ≤ŒìŒîŒïŒ∂         Brown\n",
      "11      R√≥bert    Leclerc        R√≥bert       Leclerc\n",
      "12       C@rol   d'Angelo         C@rol      d'Angelo\n",
      "13       J@ne$   Smith123         J@ne$      Smith123\n",
      "14        ùíúùìáùíæùí∂        Kim          ùíúùìáùíæùí∂           Kim\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    " \n",
    "# Define a mapping for converting special characters to nearest English characters\n",
    "def map_special_characters(char):\n",
    "    special_to_english = {\n",
    "        '√é': 'I', '√è': 'I', '√ô': 'U', '√ù': 'Y',\n",
    "        '√†': 'a', '√®': 'e', '√©': 'e', '√™': 'e', '√´': 'e',\n",
    "        '√¨': 'i', '√≤': 'o', '√¥': 'o', '√π': 'u', '√ª': 'u',\n",
    "        '√Ω': 'y', '√ø': 'y', 'ƒÅ': 'a', 'ƒì': 'e', 'ƒ´': 'i',\n",
    "        '≈ç': 'o', '≈´': 'u', '√ß': 'c', '√±': 'n', 'ƒü': 'g',\n",
    "        # Add more mappings as necessary\n",
    "    }\n",
    "    return special_to_english.get(char, char)\n",
    " \n",
    "def clean_name(name, replace_special=True):\n",
    "    cleaned_name = ''\n",
    "    \n",
    "    for char in name:\n",
    "        char_code = ord(char)\n",
    "        \n",
    "        # Check if the character is within the accepted Unicode ranges\n",
    "        if (\n",
    "            (0x0041 <= char_code <= 0x005A) or  # A-Z\n",
    "            (0x0061 <= char_code <= 0x007A) or  # a-z\n",
    "            (0x00CE <= char_code <= 0x00D6) or  # √é-√ñ\n",
    "            (0x00D9 <= char_code <= 0x00DD) or  # √ô-√ù\n",
    "            (0x00E0 <= char_code <= 0x00F6) or  # √†-√∂\n",
    "            (0x00F9 <= char_code <= 0x00FD) or  # √π-√Ω\n",
    "            (char_code == 0x00FF) or  # √ø\n",
    "            (0x0100 <= char_code <= 0x0131) or  # ƒÄ-ƒ±\n",
    "            (0x0134 <= char_code <= 0x0149) or  # ƒ¥-√µ\n",
    "            (0x014C <= char_code <= 0x0165) or  # ≈å-≈•\n",
    "            (0x0168 <= char_code <= 0x017E)     # ≈®-≈æ\n",
    "        ):\n",
    "            cleaned_name += char\n",
    "        elif replace_special:\n",
    "            # Replace special characters with their nearest English equivalents\n",
    "            cleaned_name += map_special_characters(char)\n",
    "    \n",
    "    return cleaned_name\n",
    " \n",
    "def deduplicate_names(df, fname_col='Fname', lname_col='Lname', replace_special=True):\n",
    "    # Create new columns for cleaned names\n",
    "    df['Cleaned_Fname'] = ''\n",
    "    df['Cleaned_Lname'] = ''\n",
    "    \n",
    "    # Identify records with special characters\n",
    "    for index, row in df.iterrows():\n",
    "        first_name = row[fname_col]\n",
    "        last_name = row[lname_col]\n",
    "        \n",
    "        # Clean names if they contain special characters\n",
    "        if any(not (0x0041 <= ord(c) <= 0x007A or 0x00CE <= ord(c) <= 0x017E) for c in first_name + last_name):\n",
    "            cleaned_first = clean_name(first_name, replace_special)\n",
    "            cleaned_last = clean_name(last_name, replace_special)\n",
    "            df.at[index, 'Cleaned_Fname'] = cleaned_first\n",
    "            df.at[index, 'Cleaned_Lname'] = cleaned_last\n",
    "        else:\n",
    "            df.at[index, 'Cleaned_Fname'] = first_name\n",
    "            df.at[index, 'Cleaned_Lname'] = last_name\n",
    " \n",
    "    return df\n",
    " \n",
    "# Example usage:\n",
    "data = {\n",
    "    'Fname': ['John', 'J√∂hn', 'Anna-Marie', 'Jos√©', 'M√•rk', 'El≈ºbieta', 'Andr√©', 'S√ºmmer', 'T√≥TPœÜœàŒªŒ∑‚àû', 'L√∫cia', 'AŒ±Œ≤ŒìŒîŒïŒ∂', 'R√≥bert', 'C@rol', 'J@ne$', 'ùíúùìáùíæùí∂'],\n",
    "    'Lname': ['Doe', 'D≈ì', 'O\\'Connor', 'Garc√≠a', 'Smith', 'Kowalski', 'T√≥th', 'M√ºller', 'Johnson', 'Fern√°ndez', 'Brown', 'Leclerc', 'd\\'Angelo', 'Smith123', 'Kim']\n",
    "}\n",
    " \n",
    "df = pd.DataFrame(data)\n",
    " \n",
    "# Clean the DataFrame\n",
    "cleaned_df = deduplicate_names(df)\n",
    " \n",
    "# Display the cleaned DataFrame\n",
    "print(cleaned_df[['Fname', 'Lname', 'Cleaned_Fname', 'Cleaned_Lname']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Firstname Last Name                         Email Extracted Fname  \\\n",
      "0       Adam         L             landis@lrclaw.com               l   \n",
      "1          A     Smith         asmith@ioadvisors.com               a   \n",
      "2          A     Smith     Adam.Smith@butlersnow.com            Adam   \n",
      "3        Adm     Smith      AdamSmith@butlersnow.com               A   \n",
      "4          A     Smith      AdamSmith@butlersnow.com               A   \n",
      "5          A         J       alison.jones@alston.com          alison   \n",
      "6          A         J       alison.jones@alston.com          alison   \n",
      "7          A         J        allison.jones@pnfp.com         allison   \n",
      "8          A      Rose    anedrearose@joelefrank.com               a   \n",
      "9        NaN    O'Neal       aoneal@pinecrestcap.com               a   \n",
      "10       NaN     Smith      asmith@houlihansmith.com               a   \n",
      "11    Arnold         G          agrant@reedsmith.com               a   \n",
      "12       NaN       NaN      r.oliner@duanemorris.com               r   \n",
      "13       NaN  Heidrich          ART.Heidrich@tpg.com             ART   \n",
      "14         A         M   amonaghan@graniteequity.com               a   \n",
      "15       NaN         H  Arthur-heller@higcapital.com          Arthur   \n",
      "\n",
      "   Extracted Lname  \n",
      "0            andis  \n",
      "1            smith  \n",
      "2            Smith  \n",
      "3         damSmith  \n",
      "4         damSmith  \n",
      "5            jones  \n",
      "6            jones  \n",
      "7            jones  \n",
      "8       nedrearose  \n",
      "9            oneal  \n",
      "10           smith  \n",
      "11           grant  \n",
      "12          oliner  \n",
      "13        Heidrich  \n",
      "14        monaghan  \n",
      "15          heller  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Complete name': ['Adam Smith'] * 10,\n",
    "    'Firstname': ['A', '', 'A', 'Adam', 'Adam', 'A', '', 'A', 'Adam', 'Adam'],\n",
    "    'Last name': ['Smith'] + ['Smith'] * 9,\n",
    "    'Email': [\n",
    "        'a.smith@domain.com',\n",
    "        'adam.smith@domain.com',\n",
    "        'adam_smith@domain.com',\n",
    "        'adam-smith@domain.com',\n",
    "        'asmith@domain.com',\n",
    "        'adamsmith@domain.com',\n",
    "        'asmith@domain.com',\n",
    "        'adam_smith@domain.com',\n",
    "        'adam-smith@domain.com',\n",
    "        'smith-adam@domain.com'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.read_excel(\"./data/Email extraction.xlsx\")\n",
    "\n",
    "# Function to extract Fname and Lname from email\n",
    "def extract_names(row):\n",
    "    email = row['Email']\n",
    "    first_name = row['Firstname']\n",
    "    last_name = row['Last Name']\n",
    "\n",
    "    # Adjusted regex patterns to capture various cases\n",
    "    patterns = [\n",
    "        r'(?P<Fname>[A-Za-z])\\.(?P<Lname>[A-Za-z]+)',  # Pattern 1: F.Lname\n",
    "        r'(?P<Fname>[A-Za-z]+)\\.(?P<Lname>[A-Za-z]+)',  # Pattern 2: Fname.Lname\n",
    "        r'(?P<Fname>[A-Za-z]+)_(?P<Lname>[A-Za-z]+)',  # Pattern 3: Fname_Lname\n",
    "        r'(?P<Fname>[A-Za-z]+)-(?P<Lname>[A-Za-z]+)',  # Pattern 4: Fname-Lname\n",
    "        r'(?P<Lname>[A-Za-z]+)-(?P<Fname>[A-Za-z]+)',  # Pattern 5: Lname-Fname\n",
    "        r'(?P<Fname>[A-Za-z])(?P<Lname>[A-Za-z]+)',    # Pattern 6: F.Lname (no separator)\n",
    "        r'(?P<Lname>[A-Za-z]+)@',                        # Pattern 7: Lname only\n",
    "        r'(?P<Fname>[A-Za-z]+)@',                        # Pattern 8: Fname only\n",
    "        r'(?P<Fname>[A-Za-z]+)(?P<Lname>[A-Za-z]+)@',   # Pattern 9: FnameLname without separator\n",
    "        r'(?P<Fname>[A-Za-z])(?P<Lname>[A-Za-z]+)@domain\\.com'  # Pattern 10: F.Lname with domain\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, email)\n",
    "        if match:\n",
    "            fname = match.group('Fname')\n",
    "            lname = match.group('Lname')\n",
    "            return fname, lname\n",
    "\n",
    "    return first_name, last_name  # Return defaults if no pattern matches\n",
    "\n",
    "# Apply the extraction function\n",
    "df[['Extracted Fname', 'Extracted Lname']] = df.apply(extract_names, axis=1, result_type='expand')\n",
    "\n",
    "# Display the DataFrame with extracted names\n",
    "print(df[[ 'Firstname', 'Last Name', 'Email', 'Extracted Fname', 'Extracted Lname']])\n",
    "df.to_csv(\"Email_output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Fname      Lname Cleaned_Fname Cleaned_Lname\n",
      "0         John        Doe          John           Doe\n",
      "1         J√∂hn         D≈ì          John            D≈ì\n",
      "2   Anna-Marie   O'Connor    Anna-Marie      O'Connor\n",
      "3         Jos√©     Garc√≠a          Jose        Garcia\n",
      "4         M√•rk      Smith          Mark         Smith\n",
      "5     El≈ºbieta   Kowalski      Elzbieta      Kowalski\n",
      "6        Andr√©       T√≥th         Andre          Toth\n",
      "7       S√ºmmer     M√ºller        Summer        Muller\n",
      "8    T√≥TPœÜœàŒªŒ∑‚àû    Johnson     ToTPœÜœàŒªŒ∑‚àû       Johnson\n",
      "9        L√∫cia  Fern√°ndez         Lucia     Fernandez\n",
      "10     AŒ±Œ≤ŒìŒîŒïŒ∂      Brown       AŒ±Œ≤ŒìŒîŒïŒ∂         Brown\n",
      "11      R√≥bert    Leclerc        Robert       Leclerc\n",
      "12       C@rol   d'Angelo         C@rol      d'Angelo\n",
      "13       J@ne$   Smith123         J@ne$      Smith123\n",
      "14        ùíúùìáùíæùí∂        Kim          Aria           Kim\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    " \n",
    "def remove_accents(input_str):\n",
    "    # Normalize the string to its decomposed form (NFKD)\n",
    "    normalized = unicodedata.normalize('NFKD', input_str)\n",
    "    # Build a new string without the accent characters (combining marks)\n",
    "    plain_str = ''.join(\n",
    "        char for char in normalized\n",
    "        if not unicodedata.combining(char)\n",
    "    )\n",
    "    return plain_str\n",
    " \n",
    "def clean_name(name):\n",
    "    # Use the remove_accents function to clean the name\n",
    "    return remove_accents(name)\n",
    " \n",
    "def deduplicate_names(df, fname_col='Fname', lname_col='Lname'):\n",
    "    # Create new columns for cleaned names\n",
    "    df['Cleaned_Fname'] = ''\n",
    "    df['Cleaned_Lname'] = ''\n",
    "    \n",
    "    # Identify records with special characters and clean names\n",
    "    for index, row in df.iterrows():\n",
    "        first_name = row[fname_col]\n",
    "        last_name = row[lname_col]\n",
    " \n",
    "        # Clean names using the remove_accents function\n",
    "        cleaned_first = clean_name(first_name)\n",
    "        cleaned_last = clean_name(last_name)\n",
    " \n",
    "        # Assign cleaned names back to the DataFrame\n",
    "        df.at[index, 'Cleaned_Fname'] = cleaned_first\n",
    "        df.at[index, 'Cleaned_Lname'] = cleaned_last\n",
    " \n",
    "    return df\n",
    " \n",
    "# Example usage:\n",
    "data = {\n",
    "    'Fname': ['John', 'J√∂hn', 'Anna-Marie', 'Jos√©', 'M√•rk', 'El≈ºbieta', 'Andr√©', 'S√ºmmer', 'T√≥TPœÜœàŒªŒ∑‚àû', 'L√∫cia', 'AŒ±Œ≤ŒìŒîŒïŒ∂', 'R√≥bert', 'C@rol', 'J@ne$', 'ùíúùìáùíæùí∂'],\n",
    "    'Lname': ['Doe', 'D≈ì', 'O\\'Connor', 'Garc√≠a', 'Smith', 'Kowalski', 'T√≥th', 'M√ºller', 'Johnson', 'Fern√°ndez', 'Brown', 'Leclerc', 'd\\'Angelo', 'Smith123', 'Kim']\n",
    "}\n",
    " \n",
    "df = pd.DataFrame(data)\n",
    " \n",
    "# Clean the DataFrame\n",
    "cleaned_df = deduplicate_names(df)\n",
    " \n",
    "# Display the cleaned DataFrame\n",
    "print(cleaned_df[['Fname', 'Lname', 'Cleaned_Fname', 'Cleaned_Lname']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Fname      Lname Cleaned_Fname Cleaned_Lname\n",
      "0         John        Doe          John           Doe\n",
      "1         J√∂hn         D≈ì          John             D\n",
      "2   Anna-Marie   O'Connor     AnnaMarie       OConnor\n",
      "3         Jos√©     Garc√≠a          Jose        Garcia\n",
      "4         M√•rk      Smith          Mark         Smith\n",
      "5     El≈ºbieta   Kowalski      Elzbieta      Kowalski\n",
      "6        Andr√©       T√≥th         Andre          Toth\n",
      "7       S√ºmmer     M√ºller        Summer        Muller\n",
      "8    T√≥TPœÜœàŒªŒ∑‚àû    Johnson          ToTP       Johnson\n",
      "9        L√∫cia  Fern√°ndez         Lucia     Fernandez\n",
      "10     AŒ±Œ≤ŒìŒîŒïŒ∂      Brown             A         Brown\n",
      "11      R√≥bert    Leclerc        Robert       Leclerc\n",
      "12       C@rol   d'Angelo          Crol       dAngelo\n",
      "13       J@ne$   Smith123           Jne      Smith123\n",
      "14        ùíúùìáùíæùí∂        Kim          Aria           Kim\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    # Normalize the string to its decomposed form (NFKD)\n",
    "    normalized = unicodedata.normalize('NFKD', input_str)\n",
    "    # Build a new string without the accent characters (combining marks)\n",
    "    plain_str = ''.join(\n",
    "        char for char in normalized\n",
    "        if not unicodedata.combining(char)\n",
    "    )\n",
    "    return plain_str\n",
    "\n",
    "def clean_name(name):\n",
    "    # Use the remove_accents function to clean the name\n",
    "    cleaned_name = remove_accents(name)\n",
    "    # Remove non-alphanumeric characters\n",
    "    cleaned_name = re.sub(r'[^a-zA-Z0-9\\s]', '', cleaned_name)\n",
    "    return cleaned_name\n",
    "\n",
    "def deduplicate_names(df, fname_col='Fname', lname_col='Lname'):\n",
    "    # Create new columns for cleaned names\n",
    "    df['Cleaned_Fname'] = ''\n",
    "    df['Cleaned_Lname'] = ''\n",
    "    \n",
    "    # Identify records with special characters and clean names\n",
    "    for index, row in df.iterrows():\n",
    "        first_name = row[fname_col]\n",
    "        last_name = row[lname_col]\n",
    "\n",
    "        # Clean names using the clean_name function\n",
    "        cleaned_first = clean_name(first_name)\n",
    "        cleaned_last = clean_name(last_name)\n",
    "\n",
    "        # Assign cleaned names back to the DataFrame\n",
    "        df.at[index, 'Cleaned_Fname'] = cleaned_first\n",
    "        df.at[index, 'Cleaned_Lname'] = cleaned_last\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'Fname': ['John', 'J√∂hn', 'Anna-Marie', 'Jos√©', 'M√•rk', 'El≈ºbieta', 'Andr√©', 'S√ºmmer', 'T√≥TPœÜœàŒªŒ∑‚àû', 'L√∫cia', 'AŒ±Œ≤ŒìŒîŒïŒ∂', 'R√≥bert', 'C@rol', 'J@ne$', 'ùíúùìáùíæùí∂'],\n",
    "    'Lname': ['Doe', 'D≈ì', \"O'Connor\", 'Garc√≠a', 'Smith', 'Kowalski', 'T√≥th', 'M√ºller', 'Johnson', 'Fern√°ndez', 'Brown', 'Leclerc', \"d'Angelo\", 'Smith123', 'Kim']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Clean the DataFrame\n",
    "cleaned_df = deduplicate_names(df)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(cleaned_df[['Fname', 'Lname', 'Cleaned_Fname', 'Cleaned_Lname']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name Last Name                   Email Extracted Fname  \\\n",
      "0           A     Smith     a.smith@domain.com                a   \n",
      "1         NaN     Smith  adam.smith@domain.com              NaN   \n",
      "2           A         S  adam_smith@domain.com             adam   \n",
      "3        Adam         S  adam-smith@domain.com             Adam   \n",
      "4           A         S  adam_smith@domain.com             adam   \n",
      "5        Adam         S  adam-smith@domain.com             Adam   \n",
      "6        Adam       NaN   smith-adam@domain.com            Adam   \n",
      "7        Adam         S      asmith@domain.com             Adam   \n",
      "8           A     Smith   adamsmith@domain.com                A   \n",
      "9           A     Smith      asmith@domain.com                A   \n",
      "10       Adam     Smith   adamsmith@domain.com             Adam   \n",
      "11       Adam         S   adamsmith@domain.com             Adam   \n",
      "12          A         S   adamsmith@domain.com                A   \n",
      "\n",
      "   Extracted Lname  \n",
      "0            Smith  \n",
      "1            Smith  \n",
      "2            smith  \n",
      "3            smith  \n",
      "4            smith  \n",
      "5            smith  \n",
      "6              NaN  \n",
      "7                S  \n",
      "8            Smith  \n",
      "9            Smith  \n",
      "10           Smith  \n",
      "11               S  \n",
      "12               S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Firstname': ['A', '', 'A', 'Adam', 'A', 'A', 'A', 'A', 'Adam', 'Adam', 'A', 'A', 'A'],\n",
    "    'Last name': ['Smith', 'Smith', 'S', 'S', 'Smith', 'Smith', 'Smith', 'S', 'S', 'Smith', 'S', 'S', 'Smith'],\n",
    "    'Email': [\n",
    "        'a.smith@domain.com',\n",
    "        'adam.smith@domain.com',\n",
    "        'adam_smith@domain.com',\n",
    "        'adam-smith@domain.com',\n",
    "        'asmith@domain.com',\n",
    "        'adamsmith@domain.com',\n",
    "        'asmith@domain.com',\n",
    "        'adam_smith@domain.com',\n",
    "        'adam-smith@domain.com',\n",
    "        'adamsmith@domain.com',\n",
    "        'adamsmith@domain.com',\n",
    "        'a.smith@domain.com',\n",
    "        'adamsmith@domain.com'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.read_excel(\"./data/Fname-Lname Extraction data.xlsx\")\n",
    "\n",
    "# Function to extract Fname and Lname from email\n",
    "def extract_names(row):\n",
    "    email = row['Email']\n",
    "    first_name = row['First Name']\n",
    "    last_name = row['Last Name']\n",
    "\n",
    "    # Check if there's a separator in the email\n",
    "    if re.search(r'[._-]', email):\n",
    "        # Case 1: Extract based on separators\n",
    "        patterns = [\n",
    "            r'(?P<Fname>[A-Za-z])\\.(?P<Lname>[A-Za-z]+)',  # Pattern 1: F.Lname\n",
    "            r'(?P<Fname>[A-Za-z]+)\\.(?P<Lname>[A-Za-z]+)',  # Pattern 2: Fname.Lname\n",
    "            r'(?P<Fname>[A-Za-z]+)_(?P<Lname>[A-Za-z]+)',  # Pattern 3: Fname_Lname\n",
    "            r'(?P<Fname>[A-Za-z]+)-(?P<Lname>[A-Za-z]+)',  # Pattern 4: Fname-Lname\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = re.match(pattern, email)\n",
    "            if match:\n",
    "                extracted_fname = match.group('Fname')\n",
    "                extracted_lname = match.group('Lname')\n",
    "                # Fill only if original names are empty or single character\n",
    "                if (len(str(first_name)) < 2 and extracted_fname) or first_name == '':\n",
    "                    first_name = extracted_fname\n",
    "                if (len(str(last_name)) < 2 and extracted_lname) or last_name == '':\n",
    "                    last_name = extracted_lname\n",
    "                return first_name, last_name\n",
    "\n",
    "    else:\n",
    "        # Case 2: No separator in the email\n",
    "        email_name = email.split('@')[0]  # Get the part before '@'\n",
    "\n",
    "        # Case 2A\n",
    "        if len(first_name) > 2 and len(last_name) > 2:\n",
    "            if first_name in email_name:\n",
    "                first_name = first_name\n",
    "            if last_name in email_name:\n",
    "                last_name = last_name\n",
    "\n",
    "        # Case 2B\n",
    "        if len(first_name) <= 1 or len(last_name) <= 1:\n",
    "            if len(first_name) == 1 and email_name.startswith(first_name.lower()):\n",
    "                if len(last_name) > 1 and last_name in email_name:\n",
    "                    last_name = last_name\n",
    "            # If both names are single characters or empty, leave as is\n",
    "            if len(first_name) <= 1 and len(last_name) <= 1:\n",
    "                return first_name, last_name\n",
    "\n",
    "        # Extract names from email if they are not already complete\n",
    "        if len(first_name) < 2 or len(last_name) < 2:\n",
    "            combined_name = re.sub(r'[^a-zA-Z]', '', email_name)  # Remove any non-alphabetic characters\n",
    "            if len(first_name) < 2 and combined_name:\n",
    "                first_name = combined_name[0]\n",
    "            if len(last_name) < 2 and len(combined_name) > 1:\n",
    "                last_name = combined_name[1:]\n",
    "\n",
    "    return first_name, last_name\n",
    "\n",
    "# Apply the extraction function\n",
    "df[['Extracted Fname', 'Extracted Lname']] = df.apply(extract_names, axis=1, result_type='expand')\n",
    "\n",
    "# Display the DataFrame with extracted names\n",
    "print(df[['First Name', 'Last Name', 'Email', 'Extracted Fname', 'Extracted Lname']])\n",
    "df.to_csv(\"Fname-Lname_output_new_logic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: cleaned_Fname-Lname Extraction data 1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_name_from_email(email):\n",
    "    patterns = [\n",
    "        r\"^([a-zA-Z])\\.([a-zA-Z]+)@\",  # First letter of first name . last name\n",
    "        r\"^([a-zA-Z]+)\\.([a-zA-Z]+)@\",  # First name . last name\n",
    "        r\"^([a-zA-Z]+)_([a-zA-Z]+)@\",  # First name _ last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # First name - last name\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, email)\n",
    "        if match:\n",
    "            return match.groups() if len(match.groups()) == 2 else (match.group(1), \"\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def process_file(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use CSV or Excel.\")\n",
    "    \n",
    "    if not {'First Name', 'Last Name', 'Email'}.issubset(df.columns):\n",
    "        raise ValueError(\"Missing required columns: 'FirstName', 'LastName', 'Email'\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        first_name, last_name, email = row['First Name'], row['Last Name'], row['Email']\n",
    "        \n",
    "        if pd.isna(first_name) or pd.isna(last_name) or len(str(first_name)) <= 2 or len(str(last_name)) <= 2:\n",
    "            extracted_first, extracted_last = extract_name_from_email(email)\n",
    "            \n",
    "            if (pd.isna(first_name) or len(str(first_name)) <= 2) and extracted_first:\n",
    "                df.at[index, 'First Name'] = extracted_first\n",
    "            if (pd.isna(last_name) or len(str(last_name)) <= 2) and extracted_last:\n",
    "                df.at[index, 'Last Name'] = extracted_last\n",
    "    \n",
    "    output_path = \"cleaned_\" + file_path.split('/')[-1]\n",
    "    df.to_csv(\"Fname-Lname Extraction data 1.csv\", index=False)\n",
    "    print(f\"Processed file saved as: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./data/Fname-Lname Extraction data 1.xlsx\"  # Replace with actual file path\n",
    "process_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: cleaned_Fname-Lname Extraction data 1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Final Code for Email Extraction for sepratation of First Name and Last Name\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_name_from_email(email):\n",
    "    patterns = [\n",
    "        r\"^([a-zA-Z])\\.([a-zA-Z]+)@\",  # First letter of first name . last name\n",
    "        r\"^([a-zA-Z]+)\\.([a-zA-Z]+)@\",  # First name . last name\n",
    "        r\"^([a-zA-Z]+)_([a-zA-Z]+)@\",  # First name _ last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # First name - last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # Last name - first name\n",
    "        r\"^([a-zA-Z])([a-zA-Z]+)@\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, email)\n",
    "        if match:\n",
    "            return match.groups() if len(match.groups()) == 2 else (match.group(1), \"\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def process_file(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use CSV or Excel.\")\n",
    "    \n",
    "    if not {'First Name', 'Last Name', 'Email'}.issubset(df.columns):\n",
    "        raise ValueError(\"Missing required columns: 'FirstName', 'LastName', 'Email'\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        first_name, last_name, email = row['First Name'], row['Last Name'], row['Email']\n",
    "        \n",
    "        if pd.isna(first_name) or pd.isna(last_name) or len(str(first_name)) < 2 or len(str(last_name)) < 2:\n",
    "            extracted_first, extracted_last = extract_name_from_email(email)\n",
    "            \n",
    "            if extracted_first and extracted_last:\n",
    "                if isinstance(first_name, str) and first_name and first_name[0].lower() == extracted_last[0].lower():\n",
    "                    if len(str(df.at[index, 'First Name']))<= len(extracted_last):\n",
    "                        df.at[index, 'First Name'] = extracted_last\n",
    "                    if len(str(df.at[index, 'Last Name']))<= len(extracted_last):\n",
    "                        df.at[index, 'Last Name'] = extracted_first\n",
    "                elif isinstance(last_name, str) and last_name and last_name[0].lower() == extracted_first[0].lower():\n",
    "                    if len(str(df.at[index, 'First Name']))<= len(extracted_first):\n",
    "                        df.at[index, 'First Name'] = extracted_first\n",
    "                    if len(str(df.at[index, 'Last Name']))< len(extracted_first):\n",
    "                        df.at[index, 'Last Name'] = extracted_last\n",
    "                else:\n",
    "                    if (pd.isna(first_name) or len(str(first_name)) <= 2):\n",
    "                        df.at[index, 'First Name'] = extracted_first\n",
    "                    if (pd.isna(last_name) or len(str(last_name)) <= 2):\n",
    "                        df.at[index, 'Last Name'] = extracted_last\n",
    "    \n",
    "    output_path = \"cleaned_\" + file_path.split('/')[-1]\n",
    "    df.to_csv(\"Fname-Lname Extraction data 1.csv\", index=False)\n",
    "    print(f\"Processed file saved as: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./data/Fname-Lname Extraction data 1.xlsx\"  # Replace with actual file path\n",
    "process_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: cleaned_Fname-Lname Extraction data 1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_name_from_email(email):\n",
    "    patterns = [\n",
    "        r\"^([a-zA-Z])\\.([a-zA-Z]+)@\",  # First letter of first name . last name\n",
    "        r\"^([a-zA-Z]+)\\.([a-zA-Z]+)@\",  # First name . last name\n",
    "        r\"^([a-zA-Z]+)_([a-zA-Z]+)@\",  # First name _ last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # First name - last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # Last name - first name\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, email)\n",
    "        if match:\n",
    "            return match.groups() if len(match.groups()) == 2 else (match.group(1), \"\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def process_file(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use CSV or Excel.\")\n",
    "    \n",
    "    if not {'First Name', 'Last Name', 'Email'}.issubset(df.columns):\n",
    "        raise ValueError(\"Missing required columns: 'First Name', 'Last Name', 'Email'\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        first_name, last_name, email = row['First Name'], row['Last Name'], row['Email']\n",
    "        \n",
    "        if pd.isna(first_name) or pd.isna(last_name) or len(str(first_name)) < 2 or len(str(last_name)) < 2:\n",
    "            extracted_first, extracted_last = extract_name_from_email(email)\n",
    "            \n",
    "            if extracted_first and extracted_last:\n",
    "                if isinstance(first_name, str) and first_name and first_name[0].lower() == extracted_last[0].lower():\n",
    "                    df.at[index, 'First Name'] = extracted_last\n",
    "                    df.at[index, 'Last Name'] = extracted_first\n",
    "                elif isinstance(last_name, str) and last_name and last_name[0].lower() == extracted_first[0].lower():\n",
    "                    df.at[index, 'First Name'] = extracted_first\n",
    "                    df.at[index, 'Last Name'] = extracted_last\n",
    "                else:\n",
    "                    if (pd.isna(first_name) or len(str(first_name)) < 2) or (len(extracted_first) > len(first_name)):\n",
    "                        df.at[index, 'First Name'] = extracted_first\n",
    "                    if (pd.isna(last_name) or len(str(last_name)) < 2) or (len(extracted_last) > len(last_name)):\n",
    "                        df.at[index, 'Last Name'] = extracted_last\n",
    "    \n",
    "    output_path = \"cleaned_\" + file_path.split('/')[-1]\n",
    "    df.to_csv(\"Fname-Lname Extraction data 1.csv\", index=False)\n",
    "    print(f\"Processed file saved as: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./data/Fname-Lname Extraction data 1.xlsx\"  # Replace with actual file path\n",
    "process_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name Last Name                   Email Extracted Fname  \\\n",
      "0           A     Smith     a.smith@domain.com                a   \n",
      "1         NaN       NaN   adam.smith@domain.com             NaN   \n",
      "2         NaN     Smith  adam.smith@domain.com              NaN   \n",
      "3           A         S  adam_smith@domain.com             adam   \n",
      "4        Adam         S  adam-smith@domain.com             Adam   \n",
      "5           A         S  adam_smith@domain.com             adam   \n",
      "6           A         S  smith.adam@domain.com            smith   \n",
      "7        Adam         S  adam-smith@domain.com             Adam   \n",
      "8        Adam       NaN   smith-adam@domain.com            Adam   \n",
      "9        Adam         S      smith.a@domain.com            Adam   \n",
      "10       Adam         S      asmith@domain.com             Adam   \n",
      "11       Adam         S       smith@domain.com             Adam   \n",
      "12          A     Smith        adam@domain.com                A   \n",
      "13          A     Smith   adamsmith@domain.com                A   \n",
      "14          A     Smith      asmith@domain.com                A   \n",
      "15       Adam     Smith   adamsmith@domain.com             Adam   \n",
      "16       Adam         S   adamsmith@domain.com             Adam   \n",
      "17          A         S   adamsmith@domain.com                A   \n",
      "18       Adam         S   smithadam@domain.com             Adam   \n",
      "\n",
      "   Extracted Lname  \n",
      "0            Smith  \n",
      "1              NaN  \n",
      "2            Smith  \n",
      "3            smith  \n",
      "4            smith  \n",
      "5            smith  \n",
      "6             adam  \n",
      "7            smith  \n",
      "8              NaN  \n",
      "9                a  \n",
      "10               S  \n",
      "11               S  \n",
      "12           Smith  \n",
      "13           Smith  \n",
      "14           Smith  \n",
      "15           Smith  \n",
      "16               S  \n",
      "17               S  \n",
      "18               S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    " \n",
    "# Sample dataset\n",
    "data = {\n",
    "   'Firstname': ['A', '', 'A', 'Adam', 'A', 'Adam', 'Adam', 'A', 'Adam', 'Adam', 'A', 'A', 'A'],\n",
    "   'Last name': ['Smith', 'Smith', 'S', 'S', 'Smith', 'Smith', 'Smith', 'S', 'S', 'Smith', 'S', 'S', 'Smith'],\n",
    "   'Email': [\n",
    "       'a.smith@domain.com',\n",
    "       'adam.smith@domain.com',\n",
    "       'adam_smith@domain.com',\n",
    "       'adam-smith@domain.com',\n",
    "       'asmith@domain.com',\n",
    "       'adamsmith@domain.com',\n",
    "       'asmith@domain.com',\n",
    "       'adam_smith@domain.com',\n",
    "       'adam-smith@domain.com',\n",
    "       'adamsmith@domain.com',\n",
    "       'adamsmith@domain.com',\n",
    "       'a.smith@domain.com',\n",
    "       'adamsmith@domain.com'\n",
    "   ]\n",
    "}\n",
    " \n",
    "# Create DataFrame\n",
    "df = pd.read_excel(\"./data/Fname-Lname Extraction data 1.xlsx\")\n",
    " \n",
    "# Function to extract Fname and Lname from email\n",
    "def extract_names(row):\n",
    "   email = row['Email']\n",
    "   first_name = row['First Name']\n",
    "   last_name = row['Last Name']\n",
    " \n",
    "   # Check if there's a separator in the email\n",
    "   if re.search(r'[._-]', email):\n",
    "       # Case 1: Extract based on separators\n",
    "       patterns = [\n",
    "          r'(?P<Fname>[A-Za-z])\\.(?P<Lname>[A-Za-z]+)',  # Pattern 1: F.Lname\n",
    "          r'(?P<Fname>[A-Za-z]+)\\.(?P<Lname>[A-Za-z]+)',  # Pattern 2: Fname.Lname\n",
    "          r'(?P<Fname>[A-Za-z]+)_(?P<Lname>[A-Za-z]+)',  # Pattern 3: Fname_Lname\n",
    "          r'(?P<Fname>[A-Za-z]+)-(?P<Lname>[A-Za-z]+)',  # Pattern 4: Fname-Lname\n",
    "       ]\n",
    " \n",
    "       for pattern in patterns:\n",
    "           match = re.match(pattern, email)\n",
    "           if match:\n",
    "               extracted_fname = match.group('Fname')\n",
    "               extracted_lname = match.group('Lname')\n",
    "               # Fill only if original names are empty or single character\n",
    "               if (len(str(first_name)) < 2 and extracted_fname) or first_name == '':\n",
    "                   first_name = extracted_fname\n",
    "               if (len(str(last_name)) < 2 and extracted_lname) or last_name == '':\n",
    "                   last_name = extracted_lname\n",
    "               return first_name, last_name\n",
    " \n",
    "   else:\n",
    "       # Case 2: No separator in the email\n",
    "       email_name = email.split('@')[0]  # Get the part before '@'\n",
    " \n",
    "       # Case 2A\n",
    "       if len(str(first_name)) > 2 and len(str(last_name)) > 2:\n",
    "           if first_name in email_name:\n",
    "               first_name = first_name\n",
    "           if last_name in email_name:\n",
    "               last_name = last_name\n",
    " \n",
    "       # Case 2B\n",
    "       if len(str(first_name)) <= 1 or len(str(last_name)) <= 1:\n",
    "           if len(str(first_name)) == 1 and email_name.startswith(first_name.lower()):\n",
    "               if len(str(last_name)) > 1 and last_name in email_name:\n",
    "                   last_name = last_name\n",
    "           # If both names are single characters or empty, leave as is\n",
    "           if len(str(first_name)) <= 1 and len(str(last_name)) <= 1:\n",
    "               return first_name, last_name\n",
    " \n",
    "       # Extract names from email if they are not already complete\n",
    "       if len(str(first_name)) < 2 or len(str(last_name)) < 2:\n",
    "           combined_name = re.sub(r'[^a-zA-Z]', '', email_name)  # Remove any non-alphabetic characters\n",
    "           if len(str(first_name)) < 2 and combined_name:\n",
    "               first_name = combined_name[0]\n",
    "           if len(str(last_name)) < 2 and len(combined_name) > 1:\n",
    "               last_name = combined_name[1:]\n",
    " \n",
    "   return first_name, last_name\n",
    " \n",
    "# Apply the extraction function\n",
    "df[['Extracted Fname', 'Extracted Lname']] = df.apply(extract_names, axis=1, result_type='expand')\n",
    " \n",
    "# Display the DataFrame with extracted names\n",
    "print(df[['First Name', 'Last Name', 'Email', 'Extracted Fname', 'Extracted Lname']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: cleaned_Fname-Lname Extraction data 1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_name_from_email(email):\n",
    "    patterns = [\n",
    "        r\"^([a-zA-Z])\\.([a-zA-Z]+)@\",  # First letter of first name . last name\n",
    "        r\"^([a-zA-Z]+)\\.([a-zA-Z]+)@\",  # First name . last name\n",
    "        r\"^([a-zA-Z]+)_([a-zA-Z]+)@\",  # First name _ last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # First name - last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # Last name - first name\n",
    "        r\"^([a-zA-Z])([a-zA-Z]+)@\",    # First letter of first name + last name\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, email)\n",
    "        if match:\n",
    "            if len(match.groups()) == 2:\n",
    "                first, last = match.groups()\n",
    "                if len(first) == 1 and len(last) > 1:\n",
    "                    return first + last[0], last[1:]\n",
    "                return first, last\n",
    "            else:\n",
    "                return match.group(1), \"\"\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def process_file(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use CSV or Excel.\")\n",
    "    \n",
    "    if not {'First Name', 'Last Name', 'Email'}.issubset(df.columns):\n",
    "        raise ValueError(\"Missing required columns: 'First Name', 'Last Name', 'Email'\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        first_name, last_name, email = row['First Name'], row['Last Name'], row['Email']\n",
    "        \n",
    "        if pd.isna(first_name) or pd.isna(last_name) or len(str(first_name)) < 2 or len(str(last_name)) < 2:\n",
    "            extracted_first, extracted_last = extract_name_from_email(email)\n",
    "            \n",
    "            if extracted_first and extracted_last:\n",
    "                if isinstance(first_name, str) and first_name and first_name[0].lower() == extracted_last[0].lower():\n",
    "                    if len(str(df.at[index, 'First Name'])) <= len(extracted_last):\n",
    "                        df.at[index, 'First Name'] = extracted_last\n",
    "                    if len(str(df.at[index, 'Last Name'])) <= len(extracted_last):\n",
    "                        df.at[index, 'Last Name'] = extracted_first\n",
    "                elif isinstance(last_name, str) and last_name and last_name[0].lower() == extracted_first[0].lower():\n",
    "                    if len(str(df.at[index, 'First Name'])) <= len(extracted_first):\n",
    "                        df.at[index, 'First Name'] = extracted_first\n",
    "                    if len(str(df.at[index, 'Last Name'])) < len(extracted_first):\n",
    "                        df.at[index, 'Last Name'] = extracted_last\n",
    "                else:\n",
    "                    if pd.isna(first_name) or len(str(first_name)) <= 2:\n",
    "                        df.at[index, 'First Name'] = extracted_first\n",
    "                    if pd.isna(last_name) or len(str(last_name)) <= 2:\n",
    "                        df.at[index, 'Last Name'] = extracted_last\n",
    "    \n",
    "    output_path = \"cleaned_\" + file_path.split('/')[-1]\n",
    "    df.to_csv(\"Fname-Lname Extraction data 1.csv\", index=False)\n",
    "    print(f\"Processed file saved as: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./data/Fname-Lname Extraction data 1.xlsx\"  # Replace with actual file path\n",
    "process_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Firstname Last name                 Email\n",
      "0      Adam     smith     asmith@domain.com\n",
      "1    Andrew   johnson   ajohnson@domain.com\n",
      "2   Anthony  williams  awilliams@domain.com\n",
      "3      Avis     brown     abrown@domain.com\n",
      "4  Williams    harris     wharris@gmail.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_data(df):\n",
    "    def extract_names(row):\n",
    "        # Extract components from the row\n",
    "        fname = row['Firstname'].lower()  # Convert to lowercase\n",
    "        lname = row['Last name'].lower()   # Convert to lowercase\n",
    "        email = row['Email'].lower()        # Convert to lowercase\n",
    "        \n",
    "        # Check if Lname is a single letter and Email is valid\n",
    "        if len(lname) == 1 and '@' in email:\n",
    "            # Extract the part before the '@' from the email\n",
    "            extracted_name = email.split('@')[0]  # e.g., \"wharris\"\n",
    "            \n",
    "            # Check if extracted_name starts with the first letter of Fname followed by Lname\n",
    "            if extracted_name[0] == fname[0] and extracted_name[1:].startswith(lname): \n",
    "                # Update Last name with the full last name from email\n",
    "                row['Last name'] = extracted_name[1:]# Capitalize the last name\n",
    "                return row\n",
    "\n",
    "        return row  # Return original row if no conditions are met\n",
    "\n",
    "    # Apply the processing function to each row in the DataFrame\n",
    "    df = df.apply(extract_names, axis=1)\n",
    "    return df\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.read_excel(\"./data/Data.xlsx\")\n",
    "\n",
    "# Process the DataFrame\n",
    "result_df = process_data(df)\n",
    "\n",
    "# Output the processed DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: cleaned_Fname-Lname Extraction data 1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_name_from_email(email):\n",
    "    patterns = [\n",
    "        r\"^([a-zA-Z])\\.([a-zA-Z]+)@\",  # First letter of first name . last name\n",
    "        r\"^([a-zA-Z]+)\\.([a-zA-Z]+)@\",  # First name . last name\n",
    "        r\"^([a-zA-Z]+)_([a-zA-Z]+)@\",  # First name _ last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # First name - last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # Last name - first name\n",
    "        r\"^([a-zA-Z])([a-zA-Z]+)@\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, email)\n",
    "        if match:\n",
    "            return match.groups() if len(match.groups()) == 2 else (match.group(1), \"\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def extract_names(row):\n",
    "    fname = row['First Name'].lower() if pd.notna(row['First Name']) else \"\"\n",
    "    lname = row['Last Name'].lower() if pd.notna(row['Last Name']) else \"\"\n",
    "    email = row['Email'].lower()\n",
    "    \n",
    "    extracted_first, extracted_last = extract_name_from_email(email)\n",
    "    \n",
    "    if extracted_first and extracted_last:\n",
    "        if pd.isna(row['First Name']) or len(row['First Name']) < 2:\n",
    "            row['First Name'] = extracted_first.capitalize()\n",
    "        if pd.isna(row['Last Name']) or len(row['Last Name']) < 2:\n",
    "            row['Last Name'] = extracted_last.capitalize()\n",
    "    else:\n",
    "        if len(lname) == 1 and '@' in email:\n",
    "            extracted_name = email.split('@')[0]\n",
    "            if len(extracted_name) > 1 and extracted_name[0] == fname[0] and extracted_name[1:].startswith(lname):\n",
    "                row['Last Name'] = extracted_name[1:].capitalize()\n",
    "    \n",
    "    return row\n",
    "\n",
    "def process_file(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use CSV or Excel.\")\n",
    "    \n",
    "    if not {'First Name', 'Last Name', 'Email'}.issubset(df.columns):\n",
    "        raise ValueError(\"Missing required columns: 'First Name', 'Last Name', 'Email'\")\n",
    "    \n",
    "    df = df.apply(extract_names, axis=1)\n",
    "    \n",
    "    output_path = \"cleaned_\" + file_path.split('/')[-1]\n",
    "    df.to_csv(\"Fname-Lname Extraction data 1.csv\", index=False)\n",
    "    print(f\"Processed file saved as: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./data/Fname-Lname Extraction data 1.xlsx\"  # Replace with actual file path\n",
    "process_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: cleaned_Fname-Lname Extraction data 1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_name_from_email(email):\n",
    "    patterns = [\n",
    "        r\"^([a-zA-Z])\\.([a-zA-Z]+)@\",  # First letter of first name . last name\n",
    "        r\"^([a-zA-Z]+)\\.([a-zA-Z]+)@\",  # First name . last name\n",
    "        r\"^([a-zA-Z]+)_([a-zA-Z]+)@\",  # First name _ last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # First name - last name\n",
    "        r\"^([a-zA-Z]+)-([a-zA-Z]+)@\",  # Last name - first name\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, email)\n",
    "        if match:\n",
    "            return match.groups() if len(match.groups()) == 2 else (match.group(1), \"\")\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def extract_names(row):\n",
    "    fname = row['First Name'].lower() if pd.notna(row['First Name']) else \"\"\n",
    "    lname = row['Last Name'].lower() if pd.notna(row['Last Name']) else \"\"\n",
    "    email = row['Email'].lower()\n",
    "    \n",
    "    extracted_first, extracted_last = extract_name_from_email(email)\n",
    "    \n",
    "    if extracted_first and extracted_last:\n",
    "        if pd.isna(row['First Name']) or len(row['First Name']) < 2:\n",
    "            row['First Name'] = extracted_first.capitalize()\n",
    "        if pd.isna(row['Last Name']) or len(row['Last Name']) < 2:\n",
    "            row['Last Name'] = extracted_last.capitalize()\n",
    "    else:\n",
    "        if len(lname) == 1 and '@' in email:\n",
    "            extracted_name = email.split('@')[0]\n",
    "            if len(extracted_name) > 1 and extracted_name[0] == fname[0] and extracted_name[1:].startswith(lname):\n",
    "                row['Last Name'] = extracted_name[1:].capitalize()\n",
    "    \n",
    "    return row\n",
    "\n",
    "def process_file(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use CSV or Excel.\")\n",
    "    \n",
    "    if not {'First Name', 'Last Name', 'Email'}.issubset(df.columns):\n",
    "        raise ValueError(\"Missing required columns: 'First Name', 'Last Name', 'Email'\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        first_name, last_name, email = row['First Name'], row['Last Name'], row['Email']\n",
    "        \n",
    "        if pd.isna(first_name) or pd.isna(last_name) or len(str(first_name)) < 2 or len(str(last_name)) < 2:\n",
    "            extracted_first, extracted_last = extract_name_from_email(email)\n",
    "            \n",
    "            if extracted_first and extracted_last:\n",
    "                if isinstance(first_name, str) and first_name and first_name[0].lower() == extracted_last[0].lower():\n",
    "                    if len(str(df.at[index, 'First Name'])) <= len(extracted_last):\n",
    "                        df.at[index, 'First Name'] = extracted_last.capitalize()\n",
    "                    if len(str(df.at[index, 'Last Name'])) <= len(extracted_last):\n",
    "                        df.at[index, 'Last Name'] = extracted_first.capitalize()\n",
    "                elif isinstance(last_name, str) and last_name and last_name[0].lower() == extracted_first[0].lower():\n",
    "                    if len(str(df.at[index, 'First Name'])) <= len(extracted_first):\n",
    "                        df.at[index, 'First Name'] = extracted_first.capitalize()\n",
    "                    if len(str(df.at[index, 'Last Name'])) < len(extracted_first):\n",
    "                        df.at[index, 'Last Name'] = extracted_last.capitalize()\n",
    "                else:\n",
    "                    if pd.isna(first_name) or len(str(first_name)) <= 2:\n",
    "                        df.at[index, 'First Name'] = extracted_first.capitalize()\n",
    "                    if pd.isna(last_name) or len(str(last_name)) <= 2:\n",
    "                        df.at[index, 'Last Name'] = extracted_last.capitalize()\n",
    "            else:\n",
    "                df.loc[index] = extract_names(row)\n",
    "    \n",
    "    output_path = \"cleaned_\" + file_path.split('/')[-1]\n",
    "    df.to_csv(\"Fname-Lname Extraction data 1.csv\", index=False)\n",
    "    print(f\"Processed file saved as: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./data/Fname-Lname Extraction data 1.xlsx\"  # Replace with actual file path\n",
    "process_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add email part as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.util.similarity_helper as sim_helper\n",
    "\n",
    "def group_by_last_name(df, threshold=0.85):\n",
    "    groups = []\n",
    "    for index, row in df.iterrows():\n",
    "        last_name = str(row['LastName'])\n",
    "        email = str(row.get('Email', ''))  # Ensure email is a string\n",
    "        if not last_name:  # Check if last_name is empty\n",
    "            continue  # Ensure last_name is a string\n",
    "        found_group = False\n",
    "        for group in groups:\n",
    "            # Check if the first character of the last name is the same\n",
    "            if last_name[0] == str(group[0]['LastName'])[0]:\n",
    "                if sim_helper.is_similar(last_name, str(group[0]['LastName']), threshold) or email == str(group[0].get('Email', '')):\n",
    "                    group.append(row)\n",
    "                    found_group = True\n",
    "                    break\n",
    "        if not found_group:\n",
    "            groups.append([row])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_by_first_name(groups, threshold=0.65):\n",
    "    refined_groups = []\n",
    "    for group in groups:\n",
    "        refined_group = []\n",
    "        single_letter_names = []\n",
    "        empty_first_names = []  # To store contacts with empty first names\n",
    "        \n",
    "        for contact in group:\n",
    "            first_name = str(contact.get('FirstName', ''))  # Ensure first_name is a string\n",
    "            email = str(contact.get('Email', ''))  # Ensure email is a string\n",
    "            if not first_name:\n",
    "                empty_first_names.append(contact)\n",
    "                continue\n",
    "            if len(first_name) == 1:\n",
    "                single_letter_names.append(contact)\n",
    "                continue\n",
    "            \n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0]:\n",
    "                    if sim_helper.is_similar(first_name, str(subgroup[0]['FirstName']), threshold) or email == str(subgroup[0].get('Email', '')):\n",
    "                        subgroup.append(contact)\n",
    "                        found_subgroup = True\n",
    "                        break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        \n",
    "        # Integrate single-letter names into the appropriate subgroups\n",
    "        for contact in single_letter_names:\n",
    "            first_name = str(contact.get('FirstName', ''))\n",
    "            email = str(contact.get('Email', ''))\n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0] or email == str(subgroup[0].get('Email', '')):\n",
    "                    subgroup.append(contact)\n",
    "                    found_subgroup = True\n",
    "                    break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        \n",
    "        # Add the empty first name contacts as a separate subgroup\n",
    "        if empty_first_names:\n",
    "            refined_group.append(empty_first_names)\n",
    "        \n",
    "        refined_groups.append(refined_group)\n",
    "    \n",
    "    return refined_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ids(refined_groups):\n",
    "    group_id = 1\n",
    "    subgroup_id = 1  # Initialize a global counter for SubgroupID\n",
    "    result = []\n",
    "    for group in refined_groups:\n",
    "        for subgroup in group:\n",
    "            is_duplicate = len(subgroup) > 1\n",
    "            for contact in subgroup:\n",
    "                if is_duplicate:\n",
    "                    contact['GroupID'] = group_id\n",
    "                    contact['dup_group_id'] = subgroup_id\n",
    "                else:\n",
    "                    contact['GroupID'] = group_id\n",
    "                    contact['dup_group_id'] = 999999  # No subgroup ID for unique records\n",
    "                contact['IsDuplicate'] = is_duplicate\n",
    "                result.append(contact)\n",
    "            if is_duplicate:\n",
    "                subgroup_id += 1  # Increment the global SubgroupID counter only for duplicates\n",
    "        group_id += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Full Name FirstName  LastName                      Job Title  \\\n",
      "0      Andrew Minkow    Andrew    Minkow                            CFO   \n",
      "1      Andrew Minkow         A    Minkow                            CFO   \n",
      "2   Michael Morrison   Michael  Morrison  Managing Director & Principal   \n",
      "3   Michael Morrison       NaN       NaN  Managing Director & Principal   \n",
      "12        Paul Traut       NaN       NaN                      Associate   \n",
      "\n",
      "                    Company    Office Phone                    Email  \\\n",
      "0   Pioneer Power Solutions  (212) 867-1070        aminkow@gmail.com   \n",
      "1   Pioneer Power Solutions  (212) 867-1070        aminkow@gmail.com   \n",
      "2                   4655221  (804) 591-2051  mmorrison@matrixcmg.com   \n",
      "3                   4655221  (804) 591-2051  mmorrison@matrixcmg.com   \n",
      "12               DH Capital             NaN     PTraut@dhcapital.com   \n",
      "\n",
      "     Last Contact Date State Contact Type (Entry Only)  \\\n",
      "0  2015-06-12 00:00:00    NJ                       NaN   \n",
      "1  2015-06-12 00:00:00    NJ                       NaN   \n",
      "2  2017-03-21 15:22:00    VA                       NaN   \n",
      "3  2017-03-21 15:22:00    VA                       NaN   \n",
      "12 2021-03-09 00:00:00   NaN                       NaN   \n",
      "\n",
      "               Last Activity  GroupID  dup_group_id  IsDuplicate  \n",
      "0   $3M - $5M Mezz Financing        1             1         True  \n",
      "1   $3M - $5M Mezz Financing        1             1         True  \n",
      "2         10 Minute Catch Up        2        999999        False  \n",
      "3         10 Minute Catch Up        3             2         True  \n",
      "12          1Q21 Update Call        3             2         True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"./data/SouthFiled_Contact_Input-300 records.xlsx\")\n",
    "\n",
    "broad_groups = group_by_last_name(df)\n",
    "\n",
    "# Refine by first name\n",
    "refined_groups = refine_by_first_name(broad_groups)\n",
    "\n",
    "# Assign unique IDs and flag duplicates\n",
    "processed_contacts = assign_ids(refined_groups)\n",
    "\n",
    "# Convert processed contacts back to DataFrame\n",
    "processed_df = pd.DataFrame(processed_contacts)\n",
    "print(processed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#email \n",
    "def assign_ids(refined_groups):\n",
    "    group_id = 1\n",
    "    subgroup_id = 1  # Initialize a global counter for SubgroupID\n",
    "    result = []\n",
    "    email_to_group = {}  # Dictionary to track email to group mapping\n",
    "\n",
    "    for group in refined_groups:\n",
    "        for subgroup in group:\n",
    "            is_duplicate = len(subgroup) > 1\n",
    "            for contact in subgroup:\n",
    "                email = str(contact.get('Email', '')).strip().lower()  # Convert email to string\n",
    "\n",
    "                if email in email_to_group:\n",
    "                    contact['GroupID'] = email_to_group[email]['GroupID']\n",
    "                    contact['dup_group_id'] = email_to_group[email]['dup_group_id']\n",
    "                    contact['IsDuplicate'] = True\n",
    "                else:\n",
    "                    if is_duplicate:\n",
    "                        contact['GroupID'] = group_id\n",
    "                        contact['dup_group_id'] = subgroup_id\n",
    "                        email_to_group[email] = {'GroupID': group_id, 'dup_group_id': subgroup_id}  # Map email to current group and subgroup\n",
    "                    else:\n",
    "                        contact['GroupID'] = group_id\n",
    "                        contact['dup_group_id'] = 999999  # No subgroup ID for unique records\n",
    "                    contact['IsDuplicate'] = is_duplicate\n",
    "                result.append(contact)\n",
    "\n",
    "            if is_duplicate:\n",
    "                subgroup_id += 1  # Increment the global SubgroupID counter only for duplicates\n",
    "\n",
    "        group_id += 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv('./Subset-input data for COntact - Centerbridge - 3k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Records (Only groups with more than 1 record):\n",
      "\n",
      "Group 1: Email: PTraut@dhcapital.com\n",
      "  nan nan - PTraut@dhcapital.com\n",
      "  Paul Traut - PTraut@dhcapital.com\n",
      "\n",
      "Group 2: Email: aminkow@gmail.com\n",
      "  Andrew Minkow - aminkow@gmail.com\n",
      "  A Minkow - aminkow@gmail.com\n",
      "\n",
      "Group 3: Email: dramsey@globalmna.com\n",
      "  nan nan - dramsey@globalmna.com\n",
      "  Dustin Ramsey - dramsey@globalmna.com\n",
      "\n",
      "Group 4: Email: gladdish@hydeparkcapital.com\n",
      "  Matt Gladdish - gladdish@hydeparkcapital.com\n",
      "  M Gladdish - gladdish@hydeparkcapital.com\n",
      "\n",
      "Group 5: Email: mmorrison@matrixcmg.com\n",
      "  Michael Morrison - mmorrison@matrixcmg.com\n",
      "  nan nan - mmorrison@matrixcmg.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import src.util.log_helper as log_helper\n",
    "import src.util.helper as helper\n",
    "logger = log_helper.set_get_logger(\"company_deduplication\",helper.get_logfile_name())\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('./data/SouthFiled_Contact_Input-300 records.xlsx', engine='openpyxl')\n",
    "\n",
    "def group_by_last_name(df, threshold=0.85):\n",
    "    groups = []\n",
    "    for index, row in df.iterrows():\n",
    "        last_name = str(row['LastName'])\n",
    "        if not last_name:  # Check if last_name is empty\n",
    "            continue  # Ensure last_name is a string\n",
    "        found_group = False\n",
    "        for group in groups:\n",
    "            # Check if the first character of the last name is the same\n",
    "            if last_name[0] == str(group[0]['LastName'])[0]:\n",
    "                if sim_helper.is_similar(last_name, str(group[0]['LastName']), threshold):\n",
    "                    group.append(row)\n",
    "                    found_group = True\n",
    "                    break\n",
    "        if not found_group:\n",
    "            groups.append([row])\n",
    "    return groups\n",
    "\n",
    "def refine_by_first_name(groups, threshold=0.65):\n",
    "    refined_groups = []\n",
    "    for group in groups:\n",
    "        refined_group = []\n",
    "        single_letter_names = []\n",
    "        empty_first_names = []  # To store contacts with empty first names\n",
    "        \n",
    "        for contact in group:\n",
    "            first_name = str(contact.get('FirstName', ''))  # Ensure first_name is a string\n",
    "            if not first_name:\n",
    "                empty_first_names.append(contact)\n",
    "                continue\n",
    "            if len(first_name) == 1:\n",
    "                single_letter_names.append(contact)\n",
    "                continue\n",
    "            \n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0]:\n",
    "                    if sim_helper.is_similar(first_name, str(subgroup[0]['FirstName']), threshold):\n",
    "                        subgroup.append(contact)\n",
    "                        found_subgroup = True\n",
    "                        break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        \n",
    "        # Integrate single-letter names into the appropriate subgroups\n",
    "        for contact in single_letter_names:\n",
    "            first_name = str(contact.get('FirstName', ''))\n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0]:\n",
    "                    subgroup.append(contact)\n",
    "                    found_subgroup = True\n",
    "                    break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        \n",
    "        # Add the empty first name contacts as a separate subgroup\n",
    "        if empty_first_names:\n",
    "            refined_group.append(empty_first_names)\n",
    "        \n",
    "        refined_groups.append(refined_group)\n",
    "    \n",
    "    return refined_groups\n",
    "\n",
    "\n",
    "#email \n",
    "def assign_ids(refined_groups):\n",
    "    group_id = 1\n",
    "    subgroup_id = 1  # Initialize a global counter for SubgroupID\n",
    "    result = []\n",
    "    email_to_group = {}  # Dictionary to track email to group mapping\n",
    "\n",
    "    for group in refined_groups:\n",
    "        for subgroup in group:\n",
    "            is_duplicate = len(subgroup) > 1\n",
    "            for contact in subgroup:\n",
    "                email = str(contact.get('Email', '')).strip().lower()  # Convert email to string\n",
    "\n",
    "                if email in email_to_group:\n",
    "                    contact['GroupID'] = email_to_group[email]['GroupID']\n",
    "                    contact['dup_group_id'] = email_to_group[email]['dup_group_id']\n",
    "                    contact['IsDuplicate'] = True\n",
    "                else:\n",
    "                    if is_duplicate:\n",
    "                        contact['GroupID'] = group_id\n",
    "                        contact['dup_group_id'] = subgroup_id\n",
    "                        email_to_group[email] = {'GroupID': group_id, 'dup_group_id': subgroup_id}  # Map email to current group and subgroup\n",
    "                    else:\n",
    "                        contact['GroupID'] = group_id\n",
    "                        contact['dup_group_id'] = 999999  # No subgroup ID for unique records\n",
    "                    contact['IsDuplicate'] = is_duplicate\n",
    "                result.append(contact)\n",
    "\n",
    "            if is_duplicate:\n",
    "                subgroup_id += 1  # Increment the global SubgroupID counter only for duplicates\n",
    "\n",
    "        group_id += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "# Email Grouping \n",
    "def email_grouping(df):\n",
    "    counter = 1\n",
    "    groups = []\n",
    "    for index, row in df.iterrows():\n",
    "        email = str(row['Email']).lower()\n",
    "        \n",
    "        if not email:  # Check if email is empty\n",
    "            continue  # Ensure email is a string\n",
    "        found_group = False\n",
    "        for group in groups:\n",
    "            #print(f\"counter value{counter}\")\n",
    "            if email == str(group[0]['Email']).lower():\n",
    "                print(f\"Email: {email}\")\n",
    "                print(f\"Row: {row['Email']}\")\n",
    "                print(f\"Row: {row['FirstName']}\")\n",
    "                print(f\"Row: {row['LastName']}\")\n",
    "                print(f\"Row: {row['dup_group_id']}\")\n",
    "                group.append(row)\n",
    "                found_group = True\n",
    "                break\n",
    "            counter=counter+1\n",
    "        if not found_group:\n",
    "            groups.append([row])\n",
    "    return groups\n",
    "\n",
    "# Group contacts by last name and email\n",
    "groups = group_by_last_name(df)\n",
    "\n",
    "# Refine groups by first name and email\n",
    "refined_groups = refine_by_first_name(groups)\n",
    "\n",
    "# Assign IDs to refined groups\n",
    "final_result = assign_ids(refined_groups)\n",
    "# Convert the result to a DataFrame and save to Excel\n",
    "final_df = pd.DataFrame(final_result)\n",
    "#email_grouping = email_grouping(final_df)\n",
    "\n",
    "grouped = final_df.groupby('Email')\n",
    "\n",
    "print(\"Grouped Records (Only groups with more than 1 record):\")\n",
    "group_no = 1\n",
    "for email, group_data in grouped:\n",
    "    # Check if the group contains more than one record\n",
    "    if len(group_data) > 1:\n",
    "        print(f\"\\nGroup {group_no}: Email: {email}\")\n",
    "        for _, row in group_data.iterrows():\n",
    "            print(f\"  {row['FirstName']} {row['LastName']} - {row['Email']}\")\n",
    "        group_no += 1\n",
    "\n",
    "# Save the final DataFrame to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Records:\n",
      "\n",
      "Group 1: Email: alice@example.com\n",
      "  Alice Smith - alice@example.com\n",
      "  Charlie Williams - alice@example.com\n",
      "\n",
      "Group 2: Email: bob@example.com\n",
      "  Bob Johnson - bob@example.com\n",
      "  Eva Jones - bob@example.com\n",
      "\n",
      "Group 3: Email: david@example.com\n",
      "  David Brown - david@example.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with columns FirstName, LastName, and Email\n",
    "data = [\n",
    "    {\"FirstName\": \"Alice\",   \"LastName\": \"Smith\",    \"Email\": \"alice@example.com\"},\n",
    "    {\"FirstName\": \"Bob\",     \"LastName\": \"Johnson\",  \"Email\": \"bob@example.com\"},\n",
    "    {\"FirstName\": \"Charlie\", \"LastName\": \"Williams\", \"Email\": \"alice@example.com\"},\n",
    "    {\"FirstName\": \"David\",   \"LastName\": \"Brown\",    \"Email\": \"david@example.com\"},\n",
    "    {\"FirstName\": \"Eva\",     \"LastName\": \"Jones\",    \"Email\": \"bob@example.com\"}\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group records by Email\n",
    "grouped = df.groupby('Email')\n",
    "\n",
    "# Iterate over the groups and print the output\n",
    "print(\"Grouped Records:\")\n",
    "for group_no, (email, group_data) in enumerate(grouped, start=1):\n",
    "    print(f\"\\nGroup {group_no}: Email: {email}\")\n",
    "    for _, row in group_data.iterrows():\n",
    "        print(f\"  {row['FirstName']} {row['LastName']} - {row['Email']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_last_name(df, threshold=0.85):\n",
    "    groups = []\n",
    "    for index, row in df.iterrows():\n",
    "        last_name = str(row['LastName'])\n",
    "        if not last_name:  # Check if last_name is empty\n",
    "            break  # Ensure last_name is a string\n",
    "        found_group = False\n",
    "        for group in groups:\n",
    "            # Check if the first character of the last name is the same\n",
    "            if last_name[0] == str(group[0]['LastName'])[0]:\n",
    "                if sim_helper.is_similar(last_name, str(group[0]['LastName']), threshold):\n",
    "                    group.append(row)\n",
    "                    found_group = True\n",
    "                    break\n",
    "        if not found_group:\n",
    "            groups.append([row])\n",
    "    return groups\n",
    "\n",
    "def refine_by_first_name(groups, threshold=0.65):\n",
    "    refined_groups = []\n",
    "    for group in groups:\n",
    "        refined_group = []\n",
    "        single_letter_names = []\n",
    "        empty_first_names = []  # To store contacts with empty first names\n",
    "        \n",
    "        for contact in group:\n",
    "            first_name = str(contact.get('FirstName', ''))  # Ensure first_name is a string\n",
    "            if not first_name:\n",
    "                empty_first_names.append(contact)\n",
    "                continue\n",
    "            if len(first_name) == 1:\n",
    "                single_letter_names.append(contact)\n",
    "                continue\n",
    "            \n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0]:\n",
    "                    if sim_helper.is_similar(first_name, str(subgroup[0]['FirstName']), threshold):\n",
    "                        subgroup.append(contact)\n",
    "                        found_subgroup = True\n",
    "                        break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        \n",
    "        # Integrate single-letter names into the appropriate subgroups\n",
    "        for contact in single_letter_names:\n",
    "            first_name = str(contact.get('FirstName', ''))\n",
    "            found_subgroup = False\n",
    "            for subgroup in refined_group:\n",
    "                if first_name[0] == str(subgroup[0]['FirstName'])[0]:\n",
    "                    subgroup.append(contact)\n",
    "                    found_subgroup = True\n",
    "                    break\n",
    "            if not found_subgroup:\n",
    "                refined_group.append([contact])\n",
    "        \n",
    "        # Add the empty first name contacts as a separate subgroup\n",
    "        if empty_first_names:\n",
    "            refined_group.append(empty_first_names)\n",
    "        \n",
    "        refined_groups.append(refined_group)\n",
    "    \n",
    "    return refined_groups\n",
    "\n",
    "def assign_ids(refined_groups):\n",
    "    group_id = 1\n",
    "    subgroup_id = 1  # Initialize a global counter for SubgroupID\n",
    "    result = []\n",
    "    for group in refined_groups:\n",
    "        for subgroup in group:\n",
    "            is_duplicate = len(subgroup) > 1\n",
    "            for contact in subgroup:\n",
    "                if is_duplicate:\n",
    "                    contact['GroupID'] = group_id\n",
    "                    contact['dup_group_id'] = subgroup_id\n",
    "                else:\n",
    "                    contact['GroupID'] = group_id\n",
    "                    contact['dup_group_id'] = 999999  # No subgroup ID for unique records\n",
    "                contact['IsDuplicate'] = is_duplicate\n",
    "                result.append(contact)\n",
    "            if is_duplicate:\n",
    "                subgroup_id += 1  # Increment the global SubgroupID counter only for duplicates\n",
    "        group_id += 1\n",
    "    return result,subgroup_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.util.similarity_helper as sim_helper\n",
    "\n",
    "df = pd.read_excel('./data/SouthFiled_Contact_Input-300 records.xlsx', engine='openpyxl')\n",
    "# Group contacts by last name and email\n",
    "groups = group_by_last_name(df)\n",
    "\n",
    "# Refine groups by first name and email\n",
    "refined_groups = refine_by_first_name(groups)\n",
    "\n",
    "# Assign IDs to refined groups\n",
    "final_result,subgroup_id = assign_ids(refined_groups)\n",
    "final_df = pd.DataFrame(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Full Name', 'FirstName', 'LastName', 'Job Title', 'Company',\n",
       "       'Office Phone', 'Email', 'Last Contact Date', 'State',\n",
       "       'Contact Type (Entry Only)', 'Last Activity', 'dup_group_id', 'GroupID',\n",
       "       'IsDuplicate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('./Suebset-input data for COntact - Centerbridge - 3k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Groups (only groups with more than 1 record):\n",
      "\n",
      "Email: PTraut@dhcapital.com\n",
      "  nan nan - PTraut@dhcapital.com - Dup_group_id: 2\n",
      "  Paul Traut - PTraut@dhcapital.com - Dup_group_id: 999999\n",
      "\n",
      "Email: aminkow@gmail.com\n",
      "  Andrew Minkow - aminkow@gmail.com - Dup_group_id: 1\n",
      "  A Minkow - aminkow@gmail.com - Dup_group_id: 1\n",
      "\n",
      "Email: dramsey@globalmna.com\n",
      "  nan nan - dramsey@globalmna.com - Dup_group_id: 2\n",
      "  Dustin Ramsey - dramsey@globalmna.com - Dup_group_id: 999999\n",
      "\n",
      "Email: gladdish@hydeparkcapital.com\n",
      "  Matt Gladdish - gladdish@hydeparkcapital.com - Dup_group_id: 3\n",
      "  M Gladdish - gladdish@hydeparkcapital.com - Dup_group_id: 3\n",
      "\n",
      "Email: mmorrison@matrixcmg.com\n",
      "  Michael Morrison - mmorrison@matrixcmg.com - Dup_group_id: 999999\n",
      "  nan nan - mmorrison@matrixcmg.com - Dup_group_id: 2\n"
     ]
    }
   ],
   "source": [
    "grouped = final_df.groupby('Email')\n",
    "new_group_counter = subgroup_id\n",
    "\n",
    "for email, group_data in grouped:\n",
    "    if len(group_data) > 1:\n",
    "        # Check for any non-default (non \"99999\") group id in this email group\n",
    "        non_default_ids = group_data[group_data['dup_group_id'] != \"999999\"]['dup_group_id'].unique()\n",
    "        if len(non_default_ids) > 0:\n",
    "            # Use the first non-default group id found\n",
    "            assigned_id = non_default_ids[0]\n",
    "        else:\n",
    "            # Generate a new group id if all are \"99999\"\n",
    "            assigned_id = f\"new_group_{new_group_counter}\"\n",
    "            new_group_counter += 1\n",
    "        \n",
    "        # Update records in the original DataFrame: assign the chosen id to rows with \"99999\"\n",
    "        mask = (final_df['Email'] == email) & (final_df['dup_group_id'] == \"999999\")\n",
    "        final_df.loc[mask, 'dup_group_id'] = assigned_id\n",
    "\n",
    "# Print out only groups with more than one record (grouped by email)\n",
    "print(\"Updated Groups (only groups with more than 1 record):\")\n",
    "for email, group_data in final_df.groupby('Email'):\n",
    "    if len(group_data) > 1:\n",
    "        print(f\"\\nEmail: {email}\")\n",
    "        for idx, row in group_data.iterrows():\n",
    "            print(f\"  {row['FirstName']} {row['LastName']} - {row['Email']} - Dup_group_id: {row['dup_group_id']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
